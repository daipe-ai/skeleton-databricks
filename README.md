# Daipe Framework project template

## What's inside

This is a Daipe project skeleton covering our **best practices for Databricks projects**. Daipe is focused on the following paradigms:

* anyone with basic python skills can create pipelines and improve the business logic,
* developing a standard DataLake project requires almost no engineers,
* one code for all environments (your favorite IDE + Databricks UI),
* pursue consistency as the project grows.

**Base components** to be used by everyone:

1. Configuration in YAML
1. Tables & schema management
1. Automated deployment to Databricks
1. Documentation automation

**Advanced components** to be used mostly by engineers:

1. Production releases workflow
1. Unit & pipeline testing
1. Extensions API

## Documentation

For documentation of the Daipe framework and project configurations / usages see:   
[daipe.docs.ai](https://docs.daipe.ai/data-pipelines-workflow/local-env-setup/)
