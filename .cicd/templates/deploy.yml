## DEPLOY
jobs:
  - deployment: DeployDbxNtbs
    displayName: Deploy Databricks notebooks
    environment: $(ENV)
    pool:
      vmImage: 'ubuntu-20.04'
    workspace:
      clean: all
    strategy:
      runOnce:
        deploy:
          steps:
            # checkout current repository
            - checkout: self
            - task: Bash@3
              displayName: 'Set conda-forge repository'
              inputs:
                targetType: inline
                script: |
                  set -euo pipefail
                  eval "$(conda shell.bash hook)"
                  conda config --remove channels defaults
                  conda config --append channels conda-forge
            # set orgId and Workspace Url to env based config for deployment
            - task: Bash@3
              displayName: 'Set DBX orgID and DBX url for deployment'
              inputs:
                targetType: inline
                script: |
                  set -euo pipefail
                  sed -i "s,\[Your workspace address\],$(DBX_URL),g" src/$(ls src)/_config/config_$(ENV).yaml
                  cat src/$(ls src)/_config/config_$(ENV).yaml
            # environment initialization
            - task: Bash@3
              displayName: 'Python environment initialization'
              inputs:
                targetType: inline
                script: |
                  set -euo pipefail
                  cp .env.dist .env
                  sed -i 's/DBX_TOKEN=/DBX_TOKEN=$(DBX_TOKEN)/g' .env
                  export SHELL=$SHELL
                  chmod +x env-init.sh
                  ./env-init.sh -y --verbose
            # deployment of notebooks to Dbx workspace
            - task: Bash@3
              displayName: 'Notebooks deployment'
              inputs:
                targetType: inline
                script: |
                  set -euo pipefail
                  eval "$(conda shell.bash hook)"
                  source $HOME/.poetry/env
                  conda activate $PWD/.venv
                  echo $(DEPLOY_COMMAND)
                  eval "$(DEPLOY_COMMAND)"
            - task: Bash@3
              displayName: 'Link to Databricks workspace'
              inputs:
                targetType: inline
                script: |
                  MSG=$(cat <<-END
                    Hi there!
                    -> If you are opening provided Databricks workspace for the first time you need to open it from https://portal.azure.com/
                    -> Go to $(RESOURCE_GROUP_NAME) and find there the $(DBX_WS_NAME) and Launch workspace.
                    -> Otherwise you can opet the workspace directly in the link below.
                    -> Link to deployed notebooks $(DBX_URL)
                  END
                  )
                  echo "$MSG"
